{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e20fcf-7a9a-4c00-bb07-c7a86b45e04d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, numpy as np\n",
    "\n",
    "# 1. Load the cleaned data directly from S3\n",
    "s3_path = \"s3://fcopilot-shreemathitumkur-20250708-oh/raw/shipments.parquet\"\n",
    "df = pd.read_parquet(s3_path, storage_options={'anon': False})\n",
    "\n",
    "# 2. Prepare the text column (make sure the name matches your schema)\n",
    "texts = df['delay_reason'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# 3. Load a small embedding model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4. Embed\n",
    "embeddings = model.encode(texts, batch_size=64, show_progress_bar=True)\n",
    "embeddings = np.asarray(embeddings).astype(\"float32\")  # faiss expects float32\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)           # (1000, 384) for example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d35b180-aa18-412d-bff8-399843509bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreemathitumkur/Projects/fulfillment-copilot/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/shreemathitumkur/Projects/fulfillment-copilot/.venv/lib/python3.13/site-packages/fsspec/registry.py:294: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n",
      "Batches: 100%|███████████████████████████████████████| 16/16 [00:03<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (1000, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, numpy as np\n",
    "\n",
    "s3_path = \"s3://fcopilot-shreemathitumkur-20250708-oh/raw/shipments.parquet\"\n",
    "df = pd.read_parquet(s3_path, storage_options={'anon': False})\n",
    "\n",
    "texts = df['delay_reason'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(texts, batch_size=64, show_progress_bar=True).astype(\"float32\")\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9577be7e-c0b1-4aac-ad19-c148a7eff9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index size: 1000\n",
      "Index & mapping saved ✔︎\n"
     ]
    }
   ],
   "source": [
    "import faiss, numpy as np, pathlib, pickle\n",
    "\n",
    "# 1. Build an IndexFlatL2 (simple, no training needed)\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)                 # add all 1000 vectors\n",
    "print(\"Index size:\", index.ntotal)    # should print 1000\n",
    "\n",
    "# 2. Persist to disk so you can load it later\n",
    "pathlib.Path(\"data/index\").mkdir(parents=True, exist_ok=True)\n",
    "faiss.write_index(index, \"data/index/shipments.faiss\")\n",
    "\n",
    "# 3. Save ID→row-number mapping (handy for look-ups)\n",
    "with open(\"data/index/id_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df[['delay_reason']].to_dict(\"records\"), f)\n",
    "\n",
    "print(\"Index & mapping saved ✔︎\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1217e5d-a600-43f5-8d40-3d9e512ec162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (1.11) Traffic\n",
      "2. (1.11) Traffic\n",
      "3. (1.11) Traffic\n"
     ]
    }
   ],
   "source": [
    "def search(query, k=3):\n",
    "    q_emb = model.encode([query]).astype(\"float32\")\n",
    "    distances, idx = index.search(q_emb, k)\n",
    "    for rank, (i, d) in enumerate(zip(idx[0], distances[0]), 1):\n",
    "        print(f\"{rank}. ({d:.2f}) {df.loc[i, 'delay_reason'][:120]}\")\n",
    "\n",
    "search(\"truck delayed due to traffic\", k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de434736-3d5c-49bc-b4d2-5a2eea39c9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Fulfillment Copilot)",
   "language": "python",
   "name": "fcopilot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
